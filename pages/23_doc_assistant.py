import streamlit as st

from utils.session_manager import (
    require_teacher_or_admin,
    get_current_user,
    add_message,
    get_messages,
    clear_messages,
    set_current_page,
    get_current_session_id,
)
from utils.helpers import (
    render_auth_modals,
    render_sidebar_auth_controls,
    render_sidebar_navigation,
    render_new_chat_controls,
    show_error,
    show_warning,
    show_success,
)
from ai.deepseek_handler import stream_chat_response
from database.supabase_manager import (
    get_category_by_name,
    save_conversation,
    create_document,
    add_document_chunk,
    search_document_chunks,
    list_documents,
    get_supabase_client,
)


st.set_page_config(page_title="ğŸ“„ ë¬¸ì„œ ë„ìš°ë¯¸", page_icon="ğŸ“„", layout="wide")
with st.sidebar:
    render_sidebar_navigation()
    render_sidebar_auth_controls()
render_auth_modals()
require_teacher_or_admin()
user = get_current_user()
set_current_page('doc_assistant')

st.title("ğŸ“„ ë¬¸ì„œ ë„ìš°ë¯¸ (êµì‚¬ìš©)")
st.caption("PDF/í…ìŠ¤íŠ¸ë¥¼ ì—…ë¡œë“œí•´ ì§€ì‹ ë² ì´ìŠ¤ë¡œ ë§Œë“¤ê³ , ê·¼ê±°ë¥¼ ì¸ìš©í•˜ë©° ì„¤ëª…í•©ë‹ˆë‹¤.")


# ===== Embedding model loader =====
EMBED_DIM = 384

def _load_embed_model():
    try:
        import streamlit as st
        from sentence_transformers import SentenceTransformer

        @st.cache_resource(show_spinner=False)
        def _cached_model():
            return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

        return _cached_model()
    except Exception as e:
        # ê°€ë²¼ìš´ í´ë°± ì„ë² ë”: 384ì°¨ì› ì˜ë²¡í„° ë°˜í™˜ (ì—…ë¡œë“œ/ê²€ìƒ‰ì€ ì œí•œì ì´ì§€ë§Œ ì„œë²„ ì¤‘ë‹¨ ë°©ì§€)
        show_warning(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {str(e)}. ì„ì‹œë¡œ í´ë°± ì„ë² ë”(ì˜ë²¡í„°)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 'pip install sentence-transformers' ì„¤ì¹˜ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")
        class ZeroEmbedder:
            def encode(self, texts, normalize_embeddings=True):
                # ìˆœìˆ˜ íŒŒì´ì¬ìœ¼ë¡œ ê³ ì • ì˜ë²¡í„° ë°˜í™˜ (numpy ë¯¸ì˜ì¡´)
                return [[0.0] * EMBED_DIM for _ in range(len(texts))]
        return ZeroEmbedder()

def _embed_texts(model, texts: list[str], batch_size: int = 32) -> list[list[float]]:
    try:
        # ëŒ€ëŸ‰ í…ìŠ¤íŠ¸ëŠ” ë°°ì¹˜ë¡œ ë‚˜ëˆ  ì¸ì½”ë”©í•´ ë©”ëª¨ë¦¬/CPU ê¸‰ì¦ì„ ë°©ì§€
        all_vecs: list[list[float]] = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            vecs = model.encode(batch, normalize_embeddings=True)
            # encode ê²°ê³¼ê°€ numpy ë°°ì—´ ë˜ëŠ” íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ëª¨ë‘ ì§€ì›
            try:
                all_vecs.extend([v.tolist() for v in vecs])
            except Exception:
                all_vecs.extend([list(v) for v in vecs])
        return all_vecs
    except Exception as e:
        show_error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ì˜¤ë¥˜: {str(e)}")
        return []


# ===== Text chunking =====
def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:
    text = text or ""
    chunks = []
    start = 0
    n = len(text)
    while start < n:
        end = min(start + chunk_size, n)
        chunks.append(text[start:end])
        if end == n:
            break
        start = max(0, end - overlap)
    return chunks


# ===== PDF/Text parsers =====
def parse_pdf_bytes(pdf_bytes: bytes) -> list[tuple[int, str]]:
    """Return list of (page_no, text) for each page."""
    try:
        import fitz  # PyMuPDF
    except Exception:
        show_error("PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ 'pip install pymupdf' ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return []
    try:
        doc = fitz.open(stream=pdf_bytes, filetype='pdf')
        pages = []
        for i in range(doc.page_count):
            page = doc.load_page(i)
            text = page.get_text("text") or ""
            pages.append((i + 1, text))
        return pages
    except Exception as e:
        show_error(f"PDF íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return []

def read_text_bytes(txt_bytes: bytes) -> str:
    for enc in ('utf-8', 'cp949', 'euc-kr', 'utf-16'):
        try:
            return txt_bytes.decode(enc)
        except Exception:
            continue
    return txt_bytes.decode('utf-8', errors='ignore')


# ===== Upload & index UI =====
with st.container(border=True):
    st.subheader("ë¬¸ì„œ ì—…ë¡œë“œ/ì¸ë±ì‹±")
    files = st.file_uploader("PDF ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "txt"], accept_multiple_files=True)
    if files:
        model = _load_embed_model()
        if not model:
            st.stop()
        # Supabase ì—°ê²° í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •/ì—°ê²° ì‹¤íŒ¨ ì‹œ ëª…í™•í•œ ì•ˆë‚´)
        client = get_supabase_client()
        if not client:
            show_error("Supabase ì—°ê²° ì„¤ì •(SUPABASE_URL/SUPABASE_KEY)ì´ í•„ìš”í•©ë‹ˆë‹¤. Supabase ëŒ€ì‹œë³´ë“œ SQL Editorì—ì„œ database/schema.sqlì„ ì‹¤í–‰í•´ í…Œì´ë¸”/RPCë„ ì¤€ë¹„í•˜ì„¸ìš”.")
            st.stop()
        progress = st.progress(0.0, text="ì¸ë±ì‹± ì¤€ë¹„ ì¤‘â€¦")
        total_chunks = 0
        failed_chunks = 0
        processed_files = 0
        for idx, f in enumerate(files, start=1):
            try:
                file_bytes = f.read()
                content_type = 'application/pdf' if f.type == 'application/pdf' or f.name.lower().endswith('.pdf') else 'text/plain'
                doc_row = create_document(user_id=user['id'], title=f.name, file_name=f.name, content_type=content_type)
                if not doc_row:
                    show_error(f"ë¬¸ì„œ ë©”íƒ€ ì €ì¥ ì‹¤íŒ¨: {f.name}")
                    continue

                if content_type == 'application/pdf':
                    # í˜ì´ì§€ë¥¼ í•œ ë²ˆì— ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³ , í˜ì´ì§€ë³„ë¡œ ì²­í¬ë¥¼ ìƒì„±í•˜ë©° ì œí•œì„ ì ìš©
                    page_chunks = []
                    meta_list = []
                    try:
                        import fitz  # PyMuPDF
                        pdf = fitz.open(stream=file_bytes, filetype='pdf')
                        MAX_CHUNKS = 500
                        for pno in range(pdf.page_count):
                            if len(page_chunks) >= MAX_CHUNKS:
                                show_warning(f"í˜ì´ì§€ {pno+1}ë¶€í„°ëŠ” ì²­í¬ ì œí•œ({MAX_CHUNKS})ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.")
                                break
                            page = pdf.load_page(pno)
                            ptxt = page.get_text("text") or ""
                            cks = chunk_text(ptxt)
                            for ck in cks:
                                if len(page_chunks) >= MAX_CHUNKS:
                                    break
                                page_chunks.append(ck)
                                meta_list.append({"page": pno + 1, "file": f.name})
                        pdf.close()
                    except Exception as e:
                        show_error(f"PDF íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                        page_chunks = []
                        meta_list = []
                else:
                    text = read_text_bytes(file_bytes)
                    page_chunks = chunk_text(text)
                    meta_list = [{"file": f.name} for _ in page_chunks]

                # ë„ˆë¬´ ë§ì€ ì²­í¬ëŠ” ì œí•œí•´ ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
                MAX_CHUNKS = 500
                if len(page_chunks) > MAX_CHUNKS:
                    show_warning(f"ì²­í¬ê°€ {len(page_chunks)}ê°œë¡œ ë„ˆë¬´ ë§ì•„ {MAX_CHUNKS}ê°œë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
                    page_chunks = page_chunks[:MAX_CHUNKS]
                    meta_list = meta_list[:MAX_CHUNKS]

                # embed and store (ë°°ì¹˜ ì²˜ë¦¬)
                embeddings = _embed_texts(model, page_chunks, batch_size=32)
                for ci, (ck, emb, meta) in enumerate(zip(page_chunks, embeddings, meta_list)):
                    ok = add_document_chunk(
                        document_id=doc_row['id'],
                        user_id=user['id'],
                        content=ck,
                        embedding=emb,
                        chunk_index=ci,
                        metadata=meta,
                    )
                    if ok:
                        total_chunks += 1
                    else:
                        failed_chunks += 1
                processed_files += 1
                progress.progress(processed_files / len(files), text=f"{processed_files}/{len(files)} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                show_error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜({f.name}): {str(e)}")
        if failed_chunks > 0:
            show_error(f"ì¸ë±ì‹± ì¼ë¶€ ì‹¤íŒ¨: ì´ {processed_files}ê°œ íŒŒì¼, {total_chunks} ì²­í¬ ì €ì¥, {failed_chunks} ì²­í¬ ì‹¤íŒ¨")
        else:
            show_success(f"ì¸ë±ì‹± ì™„ë£Œ: ì´ {processed_files}ê°œ íŒŒì¼, {total_chunks} ì²­í¬ ì €ì¥")

    # Show my documents
    try:
        docs = list_documents(user['id'])
        if docs:
            with st.expander("ë‚´ ë¬¸ì„œ ëª©ë¡", expanded=False):
                for d in docs:
                    st.caption(f"â€¢ {d.get('file_name')} ({d.get('content_type')}) Â· {str(d.get('created_at'))[:16]}")
        else:
            st.caption("ì•„ì§ ì—…ë¡œë“œí•œ ë¬¸ì„œê°€ ì—†ì–´ìš”.")
    except Exception:
        pass


# ===== Chat with RAG =====
st.divider()
with st.container(border=True):
    st.subheader("ë¬¸ì„œ ê¸°ë°˜ ëŒ€í™”")
    last_ai = None
    for m in get_messages():
        st.chat_message(m['role']).write(m['content'])
        if m['role'] == 'assistant':
            last_ai = m['content']

    question = st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”â€¦")
    if question:
        model = _load_embed_model()
        if not model:
            st.stop()
        add_message('user', question)

        # retrieve relevant chunks
        q_emb = _embed_texts(model, [question])
        q_vec = q_emb[0] if q_emb else None
        top_chunks = []
        if q_vec:
            top_chunks = search_document_chunks(user_id=user['id'], query_embedding=q_vec, match_count=5)

        # build context
        context_lines = []
        citations = []
        for r in top_chunks:
            meta = r.get('metadata') or {}
            origin = meta.get('file', 'ë¬¸ì„œ')
            page = meta.get('page')
            cite = f"{origin}{' p.' + str(page) if page else ''}"
            citations.append(cite)
            snippet = (r.get('content') or '').strip().replace('\n', ' ')
            snippet = snippet[:400]
            context_lines.append(f"- {cite}: {snippet}")
        context_text = "\n".join(context_lines) if context_lines else "(ê´€ë ¨ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.)"

        assistant_box = st.chat_message("assistant")
        placeholder = assistant_box.empty()
        full_text = ""
        for chunk in stream_chat_response(
            category='doc_assistant',
            grade=user.get('grade'),
            is_teacher=True,
            conversation_messages=[
                {"role": m['role'], "content": m['content']} for m in get_messages()
            ] + ([{"role": "system", "content": f"ë‹¤ìŒì€ ê´€ë ¨ ê·¼ê±° ì²­í¬ì…ë‹ˆë‹¤:\n{context_text}"}] if context_text else []),
            temperature=st.session_state.get('ai_temperature', 0.5),
            max_tokens=st.session_state.get('ai_max_tokens', 800)
        ):
            full_text += chunk or ""
            placeholder.markdown(full_text)

        if full_text.strip():
            # append citations as a small footer
            if citations:
                full_text += "\n\nì°¸ê³ : " + ", ".join(citations)
            add_message('assistant', full_text)
            cat_row = get_category_by_name('doc_assistant')
            if cat_row:
                save_conversation(
                    user_id=user['id'],
                    category_id=cat_row['id'],
                    user_message=question,
                    ai_response=full_text,
                    session_id=get_current_session_id(),
                    is_private=False
                )
            st.rerun()

col1, col2, col3 = st.columns(3)
with col1:
    if st.button("ëŒ€í™” ì§€ìš°ê¸°"):
        clear_messages()
        st.rerun()
with col2:
    st.caption("ì›ë¬¸ ê·¼ê±°ë¥¼ ì¸ìš©í•˜ê³ , ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•©ë‹ˆë‹¤.")
with col3:
    st.caption("PDF/í…ìŠ¤íŠ¸ ì—…ë¡œë“œ í›„ ì§ˆë¬¸í•˜ë©´ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹µí•´ìš”.")
    render_new_chat_controls(page_key='doc_assistant', category_name='doc_assistant')