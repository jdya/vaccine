import streamlit as st
from utils.session_manager import require_teacher_or_admin, get_current_user
from utils.session_manager import add_message, get_messages, clear_messages, set_current_page
from utils.helpers import render_auth_modals, render_sidebar_auth_controls, render_sidebar_navigation, show_error, show_success
from ai.deepseek_handler import stream_chat_response
from database.supabase_manager import get_category_by_name, save_conversation

import csv
from io import StringIO
from urllib.request import urlopen
from urllib.parse import quote
from datetime import datetime, timedelta
import json
import xml.etree.ElementTree as ET

st.set_page_config(page_title="ğŸ’¹ ì£¼ì‹ ê³ ë¯¼", page_icon="ğŸ’¹", layout="wide")
with st.sidebar:
    render_sidebar_navigation()
    render_sidebar_auth_controls()
render_auth_modals()
require_teacher_or_admin()
user = get_current_user()
set_current_page('stock_worry')

st.title("ğŸ’¹ ì£¼ì‹ ê³ ë¯¼ (ë‰´ìŠ¤/ê²€ìƒ‰/ì „ë§)")
st.caption("í‚¤ì›Œë“œ ê¸°ë°˜ ë‰´ìŠ¤ì™€ ì›¹ ê²€ìƒ‰ì„ ë³´ê³ , AIë¡œ êµìœ¡ì  ê´€ì ì˜ ì „ë§ì„ ìƒì„±í•©ë‹ˆë‹¤. íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤.")

col_a, col_b, col_c = st.columns([2, 1, 2])
with col_a:
    base_ticker = st.text_input("ì¢…ëª© ì½”ë“œ", value="AAPL", help="ë¯¸êµ­: AAPL, MSFT / í•œêµ­: 005930(ì‚¼ì„±ì „ì) ë“±")
with col_b:
    market = st.selectbox("ì‹œì¥", options=["ë¯¸êµ­", "í•œêµ­"], index=0)
with col_c:
    query_text = st.text_input("ë‰´ìŠ¤/ê²€ìƒ‰ í‚¤ì›Œë“œ", value="AAPL stock")

suffix = ".us" if market == "ë¯¸êµ­" else ".kr"
symbol = f"{base_ticker.lower()}{suffix}"

def fetch_stooq_csv(sym: str):
    try:
        url = f"https://stooq.com/q/d/l/?s={sym}&i=d"
        with urlopen(url, timeout=10) as resp:
            return resp.read().decode("utf-8", errors="ignore")
    except Exception as e:
        show_error(f"ì‹œì„¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”: {e}")
        return None

def parse_timeseries(raw_csv: str, days: int = 90):
    reader = csv.DictReader(StringIO(raw_csv))
    items = []
    for r in reader:
        try:
            dt = datetime.strptime(r["Date"], "%Y-%m-%d")
            close = float(r.get("Close") or 0)
            items.append({"date": dt, "close": close})
        except Exception:
            continue
    cutoff = datetime.now() - timedelta(days=days)
    fil = [x for x in items if x["date"] >= cutoff]
    fil.sort(key=lambda x: x["date"])  # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ
    return fil

def fetch_google_news(query: str, max_items: int = 10):
    try:
        url = f"https://news.google.com/rss/search?q={quote(query)}&hl=ko&gl=KR&ceid=KR:ko"
        with urlopen(url, timeout=10) as resp:
            xml = resp.read().decode("utf-8", errors="ignore")
        root = ET.fromstring(xml)
        items = []
        for item in root.findall(".//item")[:max_items]:
            title = (item.findtext("title") or "").strip()
            link = (item.findtext("link") or "").strip()
            pub = (item.findtext("pubDate") or "").strip()
            items.append({"title": title, "link": link, "pubDate": pub})
        return items
    except Exception as e:
        show_error(f"ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”: {e}")
        return []

def fetch_duckduckgo(query: str, max_items: int = 10):
    try:
        url = f"https://api.duckduckgo.com/?q={quote(query)}&format=json&no_redirect=1&no_html=1"
        with urlopen(url, timeout=10) as resp:
            data = json.loads(resp.read().decode("utf-8", errors="ignore"))
        results = []
        abstract = data.get("AbstractText") or data.get("Abstract") or ""
        if abstract:
            results.append({"text": abstract, "url": data.get("AbstractURL") or ""})
        for rt in (data.get("RelatedTopics") or [])[:max_items]:
            text = rt.get("Text") or rt.get("FirstURL") or ""
            url = rt.get("FirstURL") or ""
            if text:
                results.append({"text": text, "url": url})
        return results[:max_items]
    except Exception as e:
        show_error(f"ì›¹ ê²€ìƒ‰ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”: {e}")
        return []

tab_news, tab_search, tab_outlook = st.tabs(["ë‰´ìŠ¤", "ê²€ìƒ‰", "ì „ë§"])

with tab_news:
    st.subheader("ìµœì‹  ë‰´ìŠ¤")
    q = query_text.strip() or f"{base_ticker} stock"
    news = fetch_google_news(q, max_items=10)
    if news:
        for n in news:
            with st.container(border=True):
                st.markdown(f"- [{n['title']}]({n['link']})")
                if n.get('pubDate'):
                    st.caption(n['pubDate'])
    else:
        st.info("ë‰´ìŠ¤ ê²°ê³¼ê°€ ì—†ì–´ìš”. í‚¤ì›Œë“œë¥¼ ë°”ê¿”ë³´ì„¸ìš”.")

with tab_search:
    st.subheader("ì›¹ ê²€ìƒ‰ ìš”ì•½")
    q = query_text.strip() or f"{base_ticker} stock"
    results = fetch_duckduckgo(q, max_items=10)
    if results:
        for r in results:
            with st.container(border=True):
                st.write(r['text'])
                if r.get('url'):
                    st.caption(r['url'])
    else:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì ì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")

with tab_outlook:
    st.subheader("êµìœ¡ì  ê´€ì ì˜ ì „ë§")
    tone = st.radio("ë¶„ì„ í†¤", options=["ë³´ìˆ˜ì ", "ì¤‘ë¦½", "ì ê·¹ì "], index=1, horizontal=True)
    days = st.selectbox("ì°¸ì¡° ê¸°ê°„(ì‹œì„¸)", options=[30, 90, 180, 365], index=1, format_func=lambda d: f"ìµœê·¼ {d}ì¼")
    ask = st.chat_input("ì „ë§ ìš”ì²­(ì˜ˆ: ì¥ê¸° ì „ë§, ì´ìŠˆ ì˜í–¥ ë¶„ì„, ë¦¬ìŠ¤í¬/ì‹œë‚˜ë¦¬ì˜¤ ë“±)")

    # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì‹œì„¸ + ë‰´ìŠ¤ ìš”ì•½)
    ts_raw = fetch_stooq_csv(symbol)
    latest_close = None
    change_pct = None
    if ts_raw:
        series = parse_timeseries(ts_raw, days=days)
        if series:
            latest_close = series[-1]['close']
            first_close = series[0]['close']
            change_pct = ((latest_close - first_close) / first_close * 100) if first_close else None

    headlines = [n['title'] for n in fetch_google_news(query_text.strip() or base_ticker, max_items=5)]
    context_lines = [
        f"í‹°ì»¤: {base_ticker} ({market}, {symbol})",
        f"ì°¸ì¡° ê¸°ê°„: ìµœê·¼ {days}ì¼",
        f"ìµœì‹  ì¢…ê°€: {latest_close:.2f}" if latest_close is not None else "ìµœì‹  ì¢…ê°€: N/A",
        f"ê¸°ê°„ ë³€ë™ë¥ : {change_pct:.2f}%" if change_pct is not None else "ê¸°ê°„ ë³€ë™ë¥ : N/A",
        f"í—¤ë“œë¼ì¸: " + ("; ".join(headlines) if headlines else "ì—†ìŒ"),
        "ì£¼ì˜: ë³¸ ë¶„ì„ì€ êµìœ¡ì  ëª©ì ì´ë©° íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤.",
    ]

    if ask:
        enriched = "\n".join(context_lines) + "\n\nìš”ì²­: " + ask + f"\në¶„ì„ í†¤: {tone}"
        add_message('user', enriched)
        assistant_box = st.chat_message("assistant")
        placeholder = assistant_box.empty()
        full_text = ""
        temp_map = {"ë³´ìˆ˜ì ": 0.3, "ì¤‘ë¦½": 0.7, "ì ê·¹ì ": 1.0}
        for chunk in stream_chat_response(
            category='stocks',
            grade=user.get('grade'),
            is_teacher=True,
            conversation_messages=[{"role": m['role'], "content": m['content']} for m in get_messages()],
            temperature=temp_map.get(tone, 0.7),
            max_tokens=800,
        ):
            full_text += chunk or ""
            placeholder.markdown(full_text)

        if full_text.strip():
            add_message('assistant', full_text)
            cat_row = get_category_by_name('stocks')
            if cat_row:
                save_conversation(user['id'], cat_row['id'], enriched, full_text, session_id='teacher_stock_worry', is_private=False)
            st.rerun()

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ëŒ€í™” ì§€ìš°ê¸°"):
            clear_messages()
            st.rerun()
    with col2:
        st.caption("íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹ˆë©° êµìœ¡ì  ë¶„ì„ì…ë‹ˆë‹¤. ì‹¤ì œ íˆ¬ì ê²°ì •ì€ ë³¸ì¸ ì±…ì„ì…ë‹ˆë‹¤.")